{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop PD model, by Brent Oeyen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this code is to compare the following Probability of Default models\n",
    "- An IRLS logistic regression with a classic transformation of variable;\n",
    "- An elastic net logistic regression with raw numeric input variables, calibrated with scipy minize;\n",
    "- A Keras DNN binary classification algorithm with raw numeric input variables transformed with a standard score; and\n",
    "- A Keras elastic net with raw numeric input variables transformed with a standard score.\n",
    "\n",
    "The following packages are used in the implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import pandas                     as pd\n",
    "import numpy                      as np\n",
    "import scipy.optimize             as optimize\n",
    "import scipy.stats                as st\n",
    "from keras.models                 import Sequential\n",
    "from keras.layers                 import Dense\n",
    "from keras.wrappers.scikit_learn  import KerasClassifier\n",
    "from keras.layers                 import Dropout\n",
    "from keras.constraints            import maxnorm\n",
    "from keras.optimizers             import SGD\n",
    "from sklearn.model_selection      import cross_val_score\n",
    "from sklearn.preprocessing        import LabelEncoder\n",
    "from sklearn.model_selection      import StratifiedKFold\n",
    "from sklearn.preprocessing        import StandardScaler\n",
    "from sklearn.pipeline             import Pipeline\n",
    "from sklearn.calibration          import CalibratedClassifierCV\n",
    "from sklearn.linear_model         import LogisticRegression\n",
    "from sklearn.model_selection      import train_test_split\n",
    "from Codes.PD.PD_tests            import *\n",
    "from Codes.PD.Logistic_regression import *\n",
    "from Codes.PD.Feature_engineering import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset, source: \"http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "location              = os.getcwd() + '/Data/german data numeric'\n",
    "dataframe             = pd.read_csv(location, header=None, delimiter=r\"\\s+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data set into input (X) input variables and binary (Y) output variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X                     = dataframe.values[:,0:24].astype(float)\n",
    "dataframe.iloc[:, 24] = dataframe.iloc[:, 24]==2\n",
    "Y                     = dataframe.values[:,24].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform input variables with a logit transformation per quantiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled       = pd.DataFrame({'X0': FE().transform_(dataframe.iloc[:, [0,24]])})\n",
    "for i in range(1, dataframe.shape[1]-1):\n",
    " X_scaled['X'+str(i)] = FE().transform_(dataframe.iloc[:, [i,24]])\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)\n",
    "X_tr   , X_tes , Y_tr   , Y_tes  = train_test_split(X       , Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output rank of the variance of the transformed and not transformed variables as an indication of which variables contain a lot of information (high value indicates a lot of ranking power):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X0     24.0\n",
      "X1     23.0\n",
      "X2     21.0\n",
      "X3     20.0\n",
      "X4     22.0\n",
      "X5     18.0\n",
      "X6     16.0\n",
      "X7     13.0\n",
      "X8     17.0\n",
      "X9     19.0\n",
      "X10     6.5\n",
      "X11    15.0\n",
      "X12     6.5\n",
      "X13     6.5\n",
      "X14     6.5\n",
      "X15     6.5\n",
      "X16     6.5\n",
      "X17     6.5\n",
      "X18     6.5\n",
      "X19     6.5\n",
      "X20     6.5\n",
      "X21     6.5\n",
      "X22    14.0\n",
      "X23     6.5\n",
      "dtype: float64\n",
      "0     20.0\n",
      "1     23.0\n",
      "2     17.0\n",
      "3     24.0\n",
      "4     21.0\n",
      "5     19.0\n",
      "6     14.0\n",
      "7     18.0\n",
      "8     16.0\n",
      "9     22.0\n",
      "10    15.0\n",
      "11    13.0\n",
      "12     6.0\n",
      "13    12.0\n",
      "14     2.0\n",
      "15     9.0\n",
      "16     5.0\n",
      "17     4.0\n",
      "18     3.0\n",
      "19     7.0\n",
      "20    10.0\n",
      "21     1.0\n",
      "22     8.0\n",
      "23    11.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.var().rank())\n",
    "print(pd.DataFrame(X_tr).var().rank())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify whether they the transformation of variable was succesful by comparing the rank correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw input variable X0:  KendalltauResult(correlation=-0.32341244264035907, pvalue=3.9303648079470383e-28)\n",
      "Transformed input variable X0: KendalltauResult(correlation=0.054551530003972955, pvalue=0.07699078300834665)\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw input variable X0: \", st.kendalltau(Y, X[:, 0]))\n",
    "print('Transformed input variable X0:', st.kendalltau(Y, X_scaled.iloc[:, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Master Scale of 22 ratings mapped to equidistant PDs in logit space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings            = 22                                         #Number of rating grades\n",
    "PD_min             = 0.0003                                     #Minimum PD value (regulatory threshold)\n",
    "slope              = (np.log((2-PD_min)/PD_min)-0)/(ratings-1)  #Slope between min PD value and default in logit space\n",
    "MS                 = 2/(1+np.exp(slope*pd.Series(list(range(ratings)))))\n",
    "idx                = pd.IntervalIndex.from_arrays(MS[1:].append(pd.Series(0)), MS, closed='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IRLS logistic regression with a classic transformation of variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calibrate model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRLS converged after 4iterations.\n"
     ]
    }
   ],
   "source": [
    "betas_start              = np.append(np.log(Y_train.mean()/(1-Y_train.mean())), np.zeros(12))\n",
    "betas_IRLS, y_train_IRLS = logistic_regression().IRLS(betas_start, np.append(np.ones([len(X_train.index), 2]), \\\n",
    "                           X_train.iloc[:, np.r_[0:10, 11, 22]], axis=1)[:, 1:], Y_train)\n",
    "X_IRLS                   = np.append(np.ones([len(X_scaled.index), 2]), \\\n",
    "                           X_scaled.iloc[:, np.r_[0:10, 11, 22]], axis=1)[:, 1:]\n",
    "IRLS_all                 = pd.DataFrame({'PD': 1/(1+np.exp(X_IRLS.dot(-betas_IRLS)))}) \n",
    "IRLS_all['Y']            = Y\n",
    "IRLS_all['rating_PD']    = MS[idx.get_indexer(IRLS_all.PD)].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output results for a regression with the 12 highest correlated variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics: [AUC all 55.52%]\n",
      "Coefficients regression: [ 5.11903847e-01  1.22865455e-01  7.61954753e-02 -4.84788648e-04\n",
      "  3.97941005e-01 -2.36673779e-01  4.01736488e-01  4.21172675e-01\n",
      " -2.69846974e+00 -2.30495957e-01 -2.84813406e-01 -1.13340218e+00\n",
      "  1.52628712e+00]\n",
      "Jeffrey test\n",
      "                    rating_PD        PD         Y     p_val\n",
      "                        count      mean      mean          \n",
      "rating_PD                                                  \n",
      "0.14953859341903025       1.0  0.121110  0.000000  0.433984\n",
      "0.21890161217657667      90.0  0.199081  0.255556  0.092699\n",
      "0.31496223179993454     497.0  0.272987  0.261569  0.714356\n",
      "0.4426995169025332      402.0  0.357164  0.360697  0.439347\n",
      "0.6036825140620321       10.0  0.462189  0.200000  0.955955\n",
      "Portfolio              1000.0  0.301915  0.300000  0.550696\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance metrics: [AUC all %.2f%%]\" % (PD_tests().AUC(IRLS_all.Y, IRLS_all.rating_PD,0)[0]*100))\n",
    "print(\"Coefficients regression:\", betas_IRLS)\n",
    "dummy               = PD_tests().Jeffrey(IRLS_all, 'rating_PD', 'PD', 'Y')\n",
    "print('Jeffrey test')\n",
    "print(dummy.iloc[:, [0, 3, 6,  11]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the poor performance of the scaled input variables, the raw input variables are used instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRLS converged after 5iterations.\n",
      "Performance metrics: [AUC all 78.45%]\n",
      "Coefficients regression: [ 1.65181869 -0.52786127  0.02578897 -0.4140539   0.00296884 -0.14828576\n",
      " -0.13942045 -0.21361935  0.059363    0.25878264 -0.02437638  0.35144775\n",
      " -0.03601741]\n",
      "Jeffrey test\n",
      "                     rating_PD        PD         Y     p_val\n",
      "                         count      mean      mean          \n",
      "rating_PD                                                   \n",
      "0.01966854325104041        3.0  0.016135  0.000000  0.255315\n",
      "0.029760560578478736      14.0  0.025735  0.000000  0.611359\n",
      "0.04491339548733918       26.0  0.037233  0.038462  0.417974\n",
      "0.06751703372078455       53.0  0.056503  0.056604  0.462350\n",
      "0.10090929621852611       91.0  0.086010  0.109890  0.202839\n",
      "0.14953859341903025      126.0  0.124423  0.103175  0.759961\n",
      "0.21890161217657667      150.0  0.183381  0.166667  0.695860\n",
      "0.31496223179993454      149.0  0.262696  0.228188  0.830484\n",
      "0.4426995169025332       134.0  0.379745  0.417910  0.181017\n",
      "0.6036825140620321       133.0  0.523686  0.571429  0.135040\n",
      "0.7933816324488658       103.0  0.679866  0.669903  0.590438\n",
      "1.0                       18.0  0.842580  0.722222  0.912605\n",
      "Portfolio               1000.0  0.300253  0.300000  0.505136\n"
     ]
    }
   ],
   "source": [
    "betas_start              = np.append(np.log(Y_tr.mean()/(1-Y_tr.mean())), np.zeros(12))\n",
    "betas_IRLS, y_train_IRLS = logistic_regression().IRLS(betas_start, np.append(np.ones([len(X_tr), 2]), \\\n",
    "                           X_tr[:, np.r_[0:10, 11, 22]], axis=1)[:, 1:], Y_tr)\n",
    "X_IRLS                   = np.append(np.ones([len(X), 2]), \\\n",
    "                           X[:, np.r_[0:10, 11, 22]], axis=1)[:, 1:]\n",
    "IRLS_all                 = pd.DataFrame({'PD': 1/(1+np.exp(X_IRLS.dot(-betas_IRLS)))}) \n",
    "IRLS_all['Y']            = Y\n",
    "IRLS_all['rating_PD']    = MS[idx.get_indexer(IRLS_all.PD)].values\n",
    "print(\"Performance metrics: [AUC all %.2f%%]\" % (PD_tests().AUC(IRLS_all.Y, IRLS_all.rating_PD,0)[0]*100))\n",
    "print(\"Coefficients regression:\", betas_IRLS)\n",
    "dummy               = PD_tests().Jeffrey(IRLS_all, 'rating_PD', 'PD', 'Y')\n",
    "print('Jeffrey test')\n",
    "print(dummy.iloc[:, [0, 3, 6, 11]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic net logistic regression with raw numeric input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution             = optimize.minimize(fun=logistic_regression().el_logicreg, x0=betas_IRLS, args=(Y_tr, \\\n",
    "                       X_tr[:, np.r_[0:10, 11, 22]], 0.3, 0.5), method='Nelder-Mead', options={\"maxiter\":5000})\n",
    "X_LL                 = np.append(np.ones([len(X), 2]), X[:, np.r_[0:10, 11, 22]], axis=1)[:, 1:]\n",
    "LL_all               = pd.DataFrame({'PD': 1/(1+np.exp(X_LL.dot(-solution.x)))}) \n",
    "LL_all['Y']          = Y\n",
    "LL_all['rating_PD']  = MS[idx.get_indexer(LL_all.PD)].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output results for a regression with the 12 highest correlated variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results logistic regression ML: Elastic net (Lambda=0.3, L1 ratio=0.5)\n",
      "Performance metrics: [AUC all 66.13%]\n",
      "Coefficients regression: [-5.59696913e-01 -9.26444379e-02  3.18177176e-02  8.19057293e-08\n",
      "  9.69142257e-03 -7.16970386e-07  3.80225097e-03  1.56004475e-07\n",
      "  2.97328529e-02  9.33491415e-04 -3.60486743e-02 -2.27130167e-03\n",
      " -7.78605630e-02]\n",
      "Jeffrey test\n",
      "                    rating_PD        PD         Y     p_val\n",
      "                        count      mean      mean          \n",
      "rating_PD                                                  \n",
      "0.04491339548733918       1.0  0.040970  0.000000  0.255947\n",
      "0.06751703372078455      10.0  0.061351  0.100000  0.255085\n",
      "0.10090929621852611      39.0  0.085639  0.102564  0.327921\n",
      "0.14953859341903025     105.0  0.128623  0.152381  0.228300\n",
      "0.21890161217657667     224.0  0.187454  0.205357  0.243235\n",
      "0.31496223179993454     299.0  0.265383  0.304348  0.065064\n",
      "0.4426995169025332      183.0  0.373943  0.360656  0.642732\n",
      "0.6036825140620321       97.0  0.510901  0.515464  0.464503\n",
      "0.7933816324488658       37.0  0.666192  0.594595  0.822911\n",
      "1.0                       5.0  0.827102  0.800000  0.615435\n",
      "Portfolio              1000.0  0.285613  0.300000  0.156919\n"
     ]
    }
   ],
   "source": [
    "print(\"Results logistic regression ML: Elastic net (Lambda=0.3, L1 ratio=0.5)\")\n",
    "print(\"Performance metrics: [AUC all %.2f%%]\" % (PD_tests().AUC(LL_all.Y, LL_all.rating_PD,0)[0]*100))\n",
    "print(\"Coefficients regression:\", solution.x)\n",
    "dummy               = PD_tests().Jeffrey(LL_all, 'rating_PD', 'PD', 'Y')\n",
    "print('Jeffrey test')\n",
    "print(dummy.iloc[:, np.r_[0, 3, 6, 11]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras DNN with raw numeric input variables transformed with a standard score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binary():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(24, input_dim=24, activation='relu'))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Dense(24, activation='relu'))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "estimators          = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_binary, epochs=80, batch_size=16, verbose=0)))\n",
    "pipeline            = Pipeline(estimators)\n",
    "pipeline.fit(X_tr, Y_tr)\n",
    "kfold               = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "results             = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "b_pred              = pd.DataFrame(pipeline.predict_proba(X_tes))\n",
    "b_pred.columns      = ['ID', 'PD']\n",
    "b_pred['Y']         = Y_tes\n",
    "b_pred['rating_PD'] = MS[idx.get_indexer(b_pred.PD)].values\n",
    "b_all               = pd.DataFrame(pipeline.predict_proba(X))\n",
    "b_all.columns       = ['ID', 'PD']\n",
    "b_all['Y']          = Y\n",
    "b_all['rating_PD']  = MS[idx.get_indexer(b_all.PD)].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output results with all input variables being used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics: Mean Accuracy CV 75.60% (STD 3.69%) [AUC test 78.12%] [AUC all 91.05%]\n",
      "Jeffrey test\n",
      "                       rating_PD        PD         Y     p_val\n",
      "                           count      mean      mean          \n",
      "rating_PD                                                     \n",
      "0.00029999999999999976      36.0  0.000081  0.000000  0.061143\n",
      "0.0004562208354469178        8.0  0.000375  0.000000  0.062677\n",
      "0.0006937632793232519       14.0  0.000574  0.000000  0.101781\n",
      "0.0010549227058496641       10.0  0.000865  0.000000  0.105975\n",
      "0.0016039437457623122       19.0  0.001308  0.000000  0.177620\n",
      "0.002438347229665251        15.0  0.002026  0.000000  0.196403\n",
      "0.0037060190379897217       14.0  0.002993  0.142857  0.000092\n",
      "0.005630882685189334        15.0  0.004583  0.000000  0.291842\n",
      "0.00855121588022675         27.0  0.006826  0.000000  0.458799\n",
      "0.012976261070719905        23.0  0.011057  0.043478  0.082398\n",
      "0.01966854325104041         30.0  0.015950  0.000000  0.676020\n",
      "0.029760560578478736        36.0  0.024195  0.055556  0.114437\n",
      "0.04491339548733918         38.0  0.037048  0.000000  0.910767\n",
      "0.06751703372078455         63.0  0.055747  0.047619  0.579663\n",
      "0.10090929621852611         62.0  0.085026  0.032258  0.946266\n",
      "0.14953859341903025         72.0  0.124531  0.097222  0.751179\n",
      "0.21890161217657667         64.0  0.182193  0.187500  0.442752\n",
      "0.31496223179993454         79.0  0.262082  0.215190  0.827911\n",
      "0.4426995169025332          95.0  0.375557  0.368421  0.553632\n",
      "0.6036825140620321         106.0  0.526726  0.641509  0.008564\n",
      "0.7933816324488658         112.0  0.698948  0.821429  0.001575\n",
      "1.0                         62.0  0.873724  0.951613  0.021739\n",
      "Portfolio                 1000.0  0.277463  0.300000  0.056588\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance metrics: Mean Accuracy CV %.2f%% (STD %.2f%%) [AUC test %.2f%%] [AUC all %.2f%%]\" \\\n",
    "% (results.mean()*100, results.std()*100, PD_tests().AUC(b_pred.Y, b_pred.rating_PD,0)[0]*100, \\\n",
    "   PD_tests().AUC(b_all.Y, b_all.rating_PD,0)[0]*100))\n",
    "dummy               = PD_tests().Jeffrey(b_all, 'rating_PD', 'PD', 'Y')\n",
    "print('Jeffrey test')\n",
    "print(dummy.iloc[:, [0, 3, 6, 11]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras elastic net with raw numeric input variables transformed with a standard score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR                  = LogisticRegression(C=0.3, penalty='elasticnet', solver='saga', \\\n",
    "                                         l1_ratio=0.5, max_iter=1000, tol=0.001)\n",
    "scaler              = StandardScaler()\n",
    "scaler.fit(X_tr)\n",
    "LR.fit(scaler.transform(X_tr), Y_tr)\n",
    "LR_pred             = pd.DataFrame(LR.predict_proba(scaler.transform(X_tes)))\n",
    "LR_pred.columns     = ['ID', 'PD']\n",
    "LR_pred['Y']        = Y_tes\n",
    "LR_pred['rating_PD']= MS[idx.get_indexer(LR_pred.PD)].values\n",
    "LR_all              = pd.DataFrame(LR.predict_proba(scaler.transform(X)))\n",
    "LR_all.columns      = ['ID', 'PD']\n",
    "LR_all['Y']         = Y \n",
    "LR_all['rating_PD'] = MS[idx.get_indexer(LR_all.PD)].values\n",
    "results             = cross_val_score(LR, X, Y, cv=kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output results with all input variables being used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results logistic regression: Elastic net (Lambda=0.3, L1 ratio=0.5)\n",
      "Performance metrics: Mean Accuracy CV 74.90% (STD 3.59%) [AUC test 80.51%] [AUC all 81.14%]\n",
      "Coefficients regression: [[-6.57062014e-01  3.06144488e-01 -3.95271636e-01  1.51811461e-01\n",
      "  -2.35458802e-01 -1.59515437e-01 -1.11558270e-01  1.88798066e-02\n",
      "   1.64084969e-01 -2.55788551e-01 -2.20602169e-01  1.41707365e-01\n",
      "   1.77686243e-04 -7.07621914e-02 -2.10568558e-01  2.85916055e-01\n",
      "  -2.45430742e-01  2.02501524e-01  1.07027461e-01  1.97936468e-02\n",
      "  -1.89891235e-01 -1.00384192e-01 -4.87961524e-02  0.00000000e+00]]\n",
      "Jeffrey test\n",
      "                     rating_PD        PD         Y     p_val\n",
      "                         count      mean      mean          \n",
      "rating_PD                                                   \n",
      "0.00855121588022675        1.0  0.006152  0.000000  0.099766\n",
      "0.012976261070719905       2.0  0.012371  0.000000  0.187656\n",
      "0.01966854325104041        6.0  0.016602  0.000000  0.352800\n",
      "0.029760560578478736      21.0  0.024902  0.000000  0.699465\n",
      "0.04491339548733918       40.0  0.036756  0.000000  0.917488\n",
      "0.06751703372078455       60.0  0.056197  0.050000  0.549392\n",
      "0.10090929621852611       92.0  0.084127  0.065217  0.733111\n",
      "0.14953859341903025      105.0  0.122607  0.142857  0.256202\n",
      "0.21890161217657667      145.0  0.182605  0.151724  0.831822\n",
      "0.31496223179993454      130.0  0.261580  0.253846  0.573450\n",
      "0.4426995169025332       128.0  0.373936  0.359375  0.630603\n",
      "0.6036825140620321       134.0  0.518180  0.567164  0.128119\n",
      "0.7933816324488658       106.0  0.687518  0.735849  0.140962\n",
      "1.0                       30.0  0.843481  0.700000  0.978192\n",
      "Portfolio               1000.0  0.302073  0.300000  0.555007\n"
     ]
    }
   ],
   "source": [
    "print(\"Results logistic regression: Elastic net (Lambda=0.3, L1 ratio=0.5)\")\n",
    "print(\"Performance metrics: Mean Accuracy CV %.2f%% (STD %.2f%%) [AUC test %.2f%%] [AUC all %.2f%%]\" \\\n",
    "% (results.mean()*100, results.std()*100, PD_tests().AUC(LR_pred.Y, LR_pred.rating_PD,0)[0]*100, \\\n",
    "   PD_tests().AUC(LR_all.Y, LR_all.rating_PD,0)[0]*100))\n",
    "print(\"Coefficients regression:\", LR.coef_)\n",
    "dummy               = PD_tests().Jeffrey(LR_all, 'rating_PD', 'PD', 'Y')\n",
    "print('Jeffrey test')\n",
    "print(dummy.iloc[:, [0, 3, 6, 11]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Based on the results of the credit data set, transforming the input data wasn't successful on a small sample population (1K). The imbalance of the observed defaults and performing credit did not create calibration issues.\n",
    "\n",
    "The Keras library is straight forward to use and requires little development from the user. Albeit fine tuning the configuration parameters to run the models will require some time and experience with both the tool and modelling a given dependent variable. In addition, the Keras library outperforms a cinch implementation of the logistic regression's IRLS and ML elastic net method.\n",
    "The DNN model outperforms the logistic regression based on the AUC of the total population (training and test data) but doesn't on the training set. In addition, the Cross Validation (CV) score of the training set is comparable while the logistic regression produces more stable results.\n",
    "\n",
    "Considering the comparable performance between DNN and elastic net and the apprehensible results of the elastic net in contrast of the complexity of understanding the probability calculation of the DNN algorithm (not covered in this example), logistic regression with an elastic net is a preferred option for PD models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
